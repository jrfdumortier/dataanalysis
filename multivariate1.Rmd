# Basic Multivariate Regression
This chapter extends the bivariate model to a multivariate model, i.e., the case with more than one independent variable. There is also a YouTube Video associated with this section:

- [Multivariate Regression with R](https://youtu.be/pUwaaBwRk2w)

The following topics associated with multivariate regression models are covered in this chapter:

- Dummy variables
- Natural logarithm
- Functional forms
- Interaction Terms
- Multicollinearity

## Introduction
Recall the bivariate regression model with one independent and one dependent variable:
$$y=\beta_0+\beta_1 \cdot x_1+\epsilon$$
The multivariate linear regression model includes more than one independent variable and is simply an extension of the bivariate regression model:
$$y=\beta_0+\beta_1 \cdot x_1+\beta_2 \cdot x_2 + \dots + \beta_k \cdot x_k + \epsilon$$
Whether we consider the bivariate or multivariate model, the objective is always to minimize the sum of squared errors which has led to the name ordinary least square (OLS) model. The equation of a line can be determined using slope ($\beta_0$) and the intercept ($\beta1$), i.e.:
$$E(y|x_1)=\beta_0+\beta_1 \cdot x_1$$
The case of a regression model with two independent variable can still be represented in a 3-dimensional graph as depicted below 

```{r, echo=FALSE}
bhat=lm(pcconsumption~rdi+rprice,data=coffee)
sp = scatterplot3d::scatterplot3d(coffee$rdi,coffee$rprice,coffee$pcconsumption,
                                         angle=45,zlab="Per Capita Consumption",
                                         xlab="Real Disposable Income",
                                         ylab="Price")
sp$plane3d(bhat,lty.box="solid")
orig      = sp$xyz.convert(coffee$rdi,coffee$rprice,coffee$pcconsumption)
plane     = sp$xyz.convert(coffee$rdi,coffee$rprice, fitted(bhat))
i.negpos  = 1+(resid(bhat)>0)
segments(orig$x,orig$y,plane$x,plane$y,col=c("blue","red")[i.negpos],lty=1)
rm(bhat,sp,orig,plane,i.negpos)
```

The purpose of the multivariate regression model is to measure the effect of independent variables on the dependent variable. It is crucial to control for everything else that could influence the dependent variable. For example, measuring the weekly grocery bill as a function of years of education might give you a statistically significant effect for education but if income is included, the effect for education might (most likely) disappear. 

The first example involves estimating home values based on square footage and number of garage spots of a house in the 46268 ZIP code in Indianapolis. The data is contained in `indyhomes`.

```{r MVRmh2}
indyhomes46268 = subset(indyhomes,zip==46268)
bhat = lm(price~sqft+garage,data=indyhomes46268)
summary(bhat)
```

Depending on the nature of the variables, it might be necessary to scale your variables for ease of interpretation. This might be necessary if coefficients are very large or very small. A rescaling, e.g., dividing income by 1000, does affect the coefficients and the standard errors but has no effect on the t-statistics.  

## Dummy Variables
So far, independent variables were quantitative such as price, income, square footage, miles, and so on. But very often, a qualitative characteristic such as religion or gender must be modeled. For this purpose, dummy variables that can be either 0 or 1 are used. Dummy variables represent a single qualitative characteristic. For example, consider the price ($y_i$) of a car depending on miles ($x_i$) and whether the car has all-wheel drive (AWD) or rear-wheel drive (RWD). This characteristic can be modeled using a dummy variable ($d_i$). If $d_i=1$, the car has AWD and if $d_1=0$, the car has RWD. The regression equation can be written as follows:
$$y_i=\beta_0+\beta_1 \cdot x_i+\beta_2 \cdot d_i+\epsilon_i$$
his regression can theoretically be separated into two single equations:

- RWD: $y_i=\beta_0+\beta_1 \cdot x_i+\epsilon_i$
- AWD: $y_i=(\beta_0+\beta_2)+\beta_1 \cdot x_i+\epsilon_i$

To interpret the dummy variables, it is necessary to know how it is coded. In the above case, if the coefficient $\beta_2$ is positive, then the dummay variable adds to the price. That is, the coefficient $\beta_2$ represents the value of all-wheel drive. 

```{r MVRbmwdummy,echo=FALSE}
bhat = lm(price~miles+allwheeldrive,data=bmw)
summary(bhat)
```

```{r MVRbmwplot,echo=FALSE}
bmw$AWD                                 = NA
bmw$AWD[which(bmw$allwheeldrive==0)]    = "RWD"
bmw$AWD[which(bmw$allwheeldrive==1)]    = "AWD"
funAWD = function(x){
  output = bhat$coefficients[1]+bhat$coefficients[2]*x+bhat$coefficients[3]
  return(output)}
funRWD = function(x){
  output = bhat$coefficients[1]+bhat$coefficients[2]*x
  return(output)}
ggplot()+
  geom_point(data=bmw,mapping=aes(x=miles,y=price,color=AWD))+
  geom_function(fun=funAWD)+
  geom_function(fun=funRWD)+
  theme_bw()+theme(legend.title=element_blank())
rm(funAWD,funRWD,bhat)
```

## Natural Logarithm
Transforming the dependent and/or independent variables using the natural logarithm has some important and useful interpretations. Consider the following simple consumption equation in which both variables are in logarithmic form:
$$ln(consumption)=\beta_0+\beta_1 \cdot \ln(income)+\epsilon$$
In this case, $\beta_1$ is the elasticity of consumption with respect to income, i.e., a 1\% increase in income leads to a $\beta_1 \cdot 1\% $ increase in consumption. For example, if $\beta_1=0.4$, then a 1\% increase in income will rise consumption by 0.4\%. Note that the percentage increase is only an approximation for small changes.

| Dep. Var. | Indep. Var | Interpretation                                                       |
|:---------:|:----------:|:---------------------------------------------------------------------|
| $y$       | $x$        | 1 dollar change in $x$ changes y by $\hat{\beta}$ dollars            |
| $\ln(y)$  | $x$        | 1 dollar change in $x$ changes y by 100 $\times \hat{\beta}$ percent |
| $\ln(y)$  | $\ln(x)$   | 1 percent change in $x$ changes y by $\hat{\beta}$ percent           |
| $y$       | $\ln(x)$   | 1 percent change in $x$ changes y by $\hat{\beta}/100$ dollars       |

```{r}
bhat = lm(log(total)~yards+att+exp+draft1+veteran+changeteam+pbowlever,data=nfl)
summary(bhat)
```

## Functional Form
To model non-linear relationships, an independent variable can be transformed by squaring it. For example, consider the relationship between income and food expenditure. The regular OLS assumes a linear relationship in the sense that an increase in income always leads to a proportional increase in food expenditure. In realty, there is likely a flattening out of food expenditure for high incomes because only so much money can be spent on food.

```{r}
bhat = lm(log(total)~yards+att+exp+exp2+draft1+veteran+changeteam+pbowlever,data=nfl)
summary(bhat)
```

## Interaction Effects
Interaction effects are used when the influence of one independent variable depends on the level of another independent variable. Suppose that you want to measure time spent volunteering ($y$) and you think that it depends on the marital status ($x_1$), the number of children ($x_2$), and some other independent variables ($X$). So you could have the following regression equation
$$y = \beta_1 \cdot x_1 \cdot  x_2 + \beta \cdot X + \epsilon$$

$$\frac{dy}{dx}=\beta_1 x_2 + \beta_2$$



## Exercises

1. ***Ohio Schools 2*** (**): Consider the data sets `ohioincome` and `ohioscore`. In a first step, merge the two data sets by IRN. For all questions below, interpret the coefficients in terms of direction, magnitude, and statistical significance.
    a. Estimate the following equation and report the output. 
        $$score = \beta_0 + \beta_1 \cdot medianincome + \beta_2 \cdot enrollment$$
    b. Estimate the following equation. Compare your answer to the previous part. Do the coefficients change in magnitude? How do you interpret the squared term?
        $$score = \beta_0 + \beta_1 \cdot medianincome + \beta_2 \cdot enrollment + \beta_3 \cdot medianincome^2$$

2. ***Honda vs. BMW*** (***): The data sets `honda` and `bmw` contain prices and mileage of used Honda and BMW cars in the Indianapolis area. For BMW, you have a dummy variable which indicates all-wheel drive ($allwheeldrive$ = 1) or rear-wheel drive ($allwheeldrive$ = 0).
    a. Run a regression with price as the dependent variable and miles as the independent variable for both cars (separately). Report the intercept and slope coefficients. Interpret your results, e.g., how does an increase in miles affect the price of the cars. 
    b. Generate two scatter plots of the data and the fitted lines. For each car, I want the scatter plot and the fitted line in the same graph. What can you say about the difference in depreciation of the two cars.

3. ***WDI*** (*): Using the data in `wdi`, estimate the equation below for the year 2018. Report and interpret the results:
      $$fertrate = \beta_0 + \beta_1 \cdot gdp+ \beta_2 \cdot litrate$$

4. ***Retail*** (***): This exercise will demonstrate the use of dummy variables to model so-called seasonality in the data `retail`. Note that time series analysis is a fairly complex topic and this question only serves as an introduction. Using the data in `retail`, estimate the following regression model:
    $$retail = \beta_0 + \beta_1 \cdot t + \sum_{m=1}^{11} \beta_m \cdot D_m$$
where $t$ represents a simple time trend and $D_m$ are monthly dummy variables. Make sure to only include 11(!) monthly dummy variables. Is there seasonality in the data? Interpret. 

5. ***Indy Homes*** (***): The data `indyhomes` contains home values of two ZIP codes in Indianapolis. In this exercise, you will estimate the value of homes (dependent variable) based on a set of independent variables. The variables are mostly self-explanatory. The variables $levels$ and garage refers to the number of $stories$ and the garage parking spots, respectively. 
    a. Create a dummy variable called $northwest$ for the 46268 ZIP code.
    b. Report the results of the following regression equation
        $$\ln(price)=\beta_0+\beta_1 \cdot \ln(sqft)+\beta_2 \cdot northwest+\beta_3 \cdot \ln(lot)+\beta_4 \cdot bed+\beta_5 \cdot garage\\
        + \beta_6 \cdot levels+ \beta_7 \cdot northwest \cdot levels$$
    c. Interpret each coefficient from the previous part and how it affects $ln(price)$. How do you interpret the interaction term?
    d. What is the expected home value of a house in the 46228 ZIP code area with the following characteristics: 1800 sqft, 0.54 acres lot, 4 bedrooms, 3 bathrooms, 2 garage spots, and 1 story.

6. ***Pork Demand*** (**): In this exercise, you will estimate the per-capita pork demand as a function of pork prices and the prices of substitutes (beef and chicken) as well as real disposable income. Use the date `meatdemand` for this exercise. Estimate the following equation and interpret the coefficients. Are the signs of the coefficients what you would expect?
$$\ln(q_{pork}) = \beta_0 + \beta_1 \cdot \ln(p_{pork}) + \beta_2 \cdot \ln(p_{chicken}) + \beta_3 \cdot \ln(p_{beef}) + \beta_4 \cdot \ln(rdi)$$
7. ***NFL*** (***): This question will have you create a similar analysis to the one found in [Berri et al. (2011)](https://doi.org/10.1016/j.econlet.2011.02.018). The corresponding data is in `nfl`:
$$\ln(total)=\beta_0+\beta_1 \cdot yards+\beta_2 \cdot att+\beta_3 \cdot exp+\beta_4 \cdot exp^2 \\ +\beta_5 \cdot draft1+\beta_6 \cdot draft2+\beta_7 \cdot veteran+\beta_8 \cdot changeteam \\+\beta_9 \cdot pbowlever+\beta_{10} \cdot symm$$
Report the output and interpret the coefficients in terms of statistical significance and direction (i.e., sign).