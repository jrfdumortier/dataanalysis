# Probability
Probability assigns a number between 0 and 1 to a given event. The number represents the likelihood of this event occurring. To assign a probability to an event, we need to conduct an experiment which is a procedure to obtain outcomes, i.e., the results of an experiment. Suppose you want to know the probability of obtaining exactly seven heads from flipping a coin ten times. We will see later that you can easily calculate this probability but if you do not know how, you have to resort to an experiment. You have to flip a coin ten times and write down the number of heads you obtain. You then have to repeat this experiment multiple times. Each time you get one of eleven possible outcomes. If you conduct the experiment 1,000 times and 117 times the outcome is a 7, then you know the probability of obtaining seven heads from flipping a coin 10 times is around 11.7\%. 

There is also a YouTube video associated with this lecture:

- [Probability](https://youtu.be/xgKUI3QWfaw)

## Sample Spaces, Outcomes, Events, and Set Operations
A sample space is a list of all possible outcomes of an experiment and is denoted $\Omega$. Examples of sample spaces are:

- Rolling a single die: $\Omega = \{1,2,3,4,5,6\}$
- Tossing a coin: $\Omega = \{H,T\}$
- Grades: $\Omega = \{A+,A,A-, \dots, F\}$
- Number of calls to a fire station in a 24-hour period: $\Omega = \{0,1,2 \dots \}$

An event is a subset of the sample space. Examples are

- Rolling an even number: $E = \{2,4,6\}$ 
- Rolling a number less or equal to 4: $S = \{1,2,3,4\}$
- More than 5 calls to the fire station: $F = \{6,7,\dots \}$

There are several set operations and we can use Venn diagrams to illustrate them:

- **Intersection**: The intersection $W$ of two sets $X$ and $Y$ is the set of elements that are in both $X$ and $Y$. We write $W=X\cap Y$. 
- **Empty or Null Sets**: The empty set or the null set ($\emptyset$) is the set with no elements. For example, if the sets $A$ and $B$ contain no common elements then these two sets are said to be disjoint, e.g., odd and even numbers: $ A\cap B=\emptyset$.
- **Unions**: The union of two sets $A$ and $B$ is the set of all elements in one or the other of the sets. We write $C=A \cup B$.
- **Complements**: The complement of a set $X$ is the set of elements of the universal set $U$ that are not elements of $X$, and is written $X^{c}$. 

For a discrete sample space $\Omega$, the probability of an event is a non-negative number, i.e., $Pr(A) \geq 0$, for any subset $A$ of $\Omega$. In addition, we have $Pr(\Omega) = 1$, i.e., all the probabilities of the outcomes in the sample space sum up to 1.

For example, if we flip a coin, the sample space is $\Omega = \{H,T\}$. The corresponding probabilities are $Pr(H)=0.5$ and $Pr(T)=0.5$. The sum of both is equal to 1. Keep in mind that $Pr(A^c)=1-Pr(A)$. It is sometimes easier to calculate the complement of an event than the event itself. If $A,B, C,\dots$ is a finite or infinite sequence of mutually exclusive events --- that is events which cannot happen at the same time --- from the sample space $\Omega$, then 
$$P\left(A \cup B \cup C \cup \cdots \right)=P(A)+P(B)+P(C)+\cdots$$
To illustrate this, suppose you are flipping a coin three times. The eight events in $\Omega$ are
$$\Omega = \{HHH,HHT,HTH,HTT,THH,THT,TTH,TTT\}$$
The probability of each event is equally likely, i.e., 
$$Pr\left(E_i \right)=1/8$$
for $i=1,2,3,\dots,8$. If your event of interest $A$ is that exactly two of the three tosses results are heads, then $A=\{HHT,HTH,THH\}$. By summing up the probabilities associated with those events, we find that $Pr(A)$: 
$$Pr(A)=Pr(HHT)+Pr(HTH)+Pr(THH)=\frac{1}{8} +\frac{1}{8} +\frac{1}{8} =\frac{3}{8}$$
Note that the same result can be obtained by using a probability tree. A probability tree has the advantage that it represents the possible outcome and probabilities in a graphical manner.

## Probability of a Union
For any two events $A$ and $B$, we have the probability of a union (also known as the addition rule) which states that the probability of $A$ or $B$ occurring can be written as:
$$Pr(A \cup B)=P(A)+P(B)-P(A \cap B)$$
If $Pr(A \cap B)=0$, then we call them disjoint events. 

For example, suppose that researchers are interested in the substances found in people's blood. Let $A=\{Alcohol\}$, $B=\{Cocaine \}$, and $A \cap B = \{Both \}$. Assume that the probabilities are as follows:
$$Pr(A)=0.86\\
Pr(B)=0.35\\
Pr(A \cap B)=0.29$$
Hence, $Pr(A \cup B)$ is calculated as follows:
$$Pr(A \cup B)= 0.86+0.35-0.29 = 0.92$$ 
If you are intrigued by this example on how to measure drug consumption, check out this [EU Project](https://www.emcdda.europa.eu/topics/pods/waste-water-analysis_en). 

For a second example, assume the following events taken from the police by controlling semi-trucks: $A=\{\text{faulty breaks}\}$, $B=\{\text{bad tires}\}$, and $A \cup B =\{\text{faulty breaks and/or bad tires}\}$. Let the probabilities be as follows:
$$Pr(A)=0.23\\
Pr(B)=0.24\\
Pr(A \cap B)=0.09$$
Using the above equation, we can determine that $P(A \cup B)=0.23+0.24-0.09=0.38$. Note that if the events are mutually exclusive, the term $Pr(A \cap B)$ is equal to 0. 

Lastly, consider the data below on the gate arrival of airplanes during a week at a mid-sized airport. Everything not within +/- 10 minutes is considered not on time. $Flights$ represents the total number of arriving flights which is 275. 

| Arrival                    | Event | Flights | Probability |
|:---------------------------|:-----:|:-------:|:-----------:|
| Less than 10 minutes early |   A   |    55   |     0.20    |
| Within +/- 10 minutes      |   B   |   121   |     0.44    |
| More than 10 minutes late  |   C   |    99   |     0.36    |

The probability of a flight not begin on time is calculated as follows:
$$Pr(A \cup C)=0.2+0.36=0.56$$

## Probability of an Intersection   
To find the probability that events $A$ and $B$ occur, we have to use the multiplication rule (i.e., probability of the intersection) which is written as follows:
$$Pr(A \cap B) = P(A) \cdot P(B)$$
For the multiplication rule to hold, the two events must be independent! The multiplication rule for dependent events will be introduced in more detail later but can be written as follows:
$$Pr(A \cap B) = Pr(A) \cdot Pr(B|A)$$
where $Pr(B|A)$ is the probability of $A$ given that even $B$ occurred. 

Suppose you have 16 polo shirts in your closet with your company's logo. Nine of them are green and seven are blue. In the morning, you get dressed in the dark and randomly grab a shirt two days in a row (without doing laundry). What is the probability that both shirts are blue? Define the events $B_i$ and $G_i$ as grabbing a blue and green shirt, respectively on day $i$. In this case, the probabilities are as follows:
$$Pr(B_1) = 7/16\\
Pr(B_2|B_1) = 6/15$$ 
Thus, 
$$Pr(B_1 \cap B_2) = Pr(B_1) \cdot Pr(B_2|B_1) = 7/16 \cdot 6/15 = 0.175$$ 
If you are interested in the probability to get a 6 on roll 1 (event $A$) and a 6 on roll 2 (event $B$). This is written as $Pr(A) \cdot Pr(B) = 1/6 \cdot 1/6 = 1/36$. This can also be expressed as a joint probability. The joint probability calculates the likelihood of two or more events happening at the same time. 

Let $A=\{Hearts\}$ and $B=\{Queen\}$. Then the joint probability is the likelihood of drawing the Queen of Hearts from a deck of cards. This joint probability can be calculated as follows:
$$Pr(A) = \frac{1}{4}\\
  Pr(B) = \frac{4}{52}\\
  Pr(A \cap B) = Pr(A) \cdot Pr(B) = \frac{1}{52}$$
Let event $A$ be that the first child is a girl and let event $B$ be the second child being a girl. What is the sample space for the gender of the two kids? Given the sample space of $\Omega = \{FF,FM,MF,MM\}$, we have $Pr(A)=0.5$, $Pr(B) = 0.5$, $Pr(A \cup B)=0.5+0.5-0.25$, and $Pr(A \cap B)=0.25$. 

## Conditional Probability
In the previous section, we have seen how to determine the probability of simple events. In this section, we will learn how to calculate the probability of an event knowing that some other event happened before. We call this *conditional probability*, i.e., what can we say about an event if the sample space changes? Consider the following examples:

- What is the probability of a person earning more than \$150,000 given graduation from Harvard Law School? 
- What is the probability of a person getting arrested given a prior arrest? 
- What is the probability of getting an *A* in graduate statistics given an undergraduate degree in mathematics? 
- What is the probability of receiving a grant from a funding agency given prior funding from the same agency? 

The conditional probability of event $A$ given that event $B$ happened is expressed as $Pr(A|B)$. Given event $B$ such that $Pr(B)>0$ and any other event $A$, we define the conditional probability of $A$ given $B$ as:
$$Pr(A|B)=\frac{Pr(A\cap B)}{Pr(B)}$$
Rearrangement of the terms from the conditional probability definition leads to the multiplication rule for dependent events:
$$Pr(A\cap B) = Pr(A|B) \cdot Pr(B)$$
Let us consider a couple of examples to illustrate this concept. Consider the following table relating the quality of the service (from an electrician) received to the years of experience.

|                | Good service | Bad Service | Total |
|----------------|:------------:|:-----------:|:-----:|
| Over 10 years  |      16      |      4      |   50  |
| Below 10 years |      10      |      20     |   30  |
| Total          |      26      |      24     |   50  |

Define the event "good service" as $G$ and "more than 10 years of experience" as $E$. What is $Pr(G)$, $Pr(G|E)$?, $Pr(E)$?

Next, consider rolling a die and the interest in the probability of a 1 given that an odd number was obtained. Let event $A$ be "observe a 1" and event $B$ be "observe an odd number". The probability of interest is $Pr(A|B)$. The event $A\cap B$ requires the observance of both a 1 and an odd number. In this instance, $A\subset B$ so $A\cap B=A$ and $Pr(A \cap B)=Pr(A)=1/6$. Also, $Pr(B)=1/2$ and, using the definition,
$$Pr(A|B) = \frac{Pr(A \cap B)}{Pr(B)} =\frac{1/6}{1/2} = \frac{1}{3}$$
In the last example, a box with red and black balls is considered. The box contains *r* red balls labeled $1,2,3,\dots,r$ and *b* black balls labeled $1,2,3,\dots,b$. If a ball from the box is known to be red, what is the probability it is the red ball labeled 1, i.e., $Pr(B|A)$? Let event $A$ be "observe a red ball" and event $B$ be "observe a 1". The probability of $A$ is $Pr(A)=r/(r+b)$ and the probability of a red ball with the number 1 on it is $Pr(A \cap B)=1/(r+b)$. Then the probability that the ball is red and labeled 1 given that it is red is given by
$$Pr(B|A)=\frac{Pr(A\cap B)}{Pr(A)} =\frac{1/(r+b)}{r/(r+b)} = \frac{1}{r}$$
This differs from the probability of $B$ (a 1 on the ball) which is given by $Pr(B)=2/(r+b)$.

## Independence
Two events are said to be independent if $Pr(A\cap B)=Pr(A) \cdot Pr(B)$. The events $A$ and $B$ are independent if knowledge of $B$ does not affect the probability of $A$. This can be written in terms of conditional probability as
$$Pr(A|B)=Pr(A)\\
  Pr(B|A)=Pr(B)$$
The probability of both events should be positive because division by zero is meaningless. Remember that $Pr(A|B)=Pr(A\cap B)/Pr(B)$ and $Pr(B|A)=Pr(A\cap B)/Pr(B)$.

Suppose you are rolling a red die and a green die. Let event $A$ be "4 on the red die" and event $B$ is "sum of the dice is odd". What is $Pr(A)$, $Pr(B)$, and $Pr(A \cap B)$? Are $A$ and $B$ independent? The table below displays all possible outcomes and can help to calculate the probabilities.

|         | Green                          ||||||
|---------|:-----:|:---:|:---:|:---:|:---:|:---:|
| **Red** |   1   |  2  |  3  |  4  |  5  |  6  |
| 1       |  1,1  | 1,2 | 1,3 | 1,4 | 1,5 | 1,6 |
| 2       |  2,1  | 2,2 | 2,3 | 2,4 | 2,5 | 2,6 |
| 3       |  3,1  | 3,2 | 3,3 | 3,4 | 3,5 | 3,6 |
| 4       |  4,1  | 4,2 | 4,3 | 4,4 | 4,5 | 4,6 |
| 5       |  5,1  | 5,2 | 5,3 | 5,4 | 5,5 | 5,6 |
| 6       |  6,1  | 6,2 | 6,3 | 6,4 | 6,5 | 6,6 |

The probabilities are as follows:
$$Pr(A)=6/36=1/6\\
  Pr(B)=18/36 = 1/2\\
  Pr(A\cap B) = 3/36 = 1/12$$
To check for independence, multiply $Pr(A)$ and $Pr(B)$ as follows
$$Pr(A) \cdot Pr(B)=\left(\frac{1}{6}\right)\left(\frac{1}{2}\right)=\frac{1}{12}$$
Next consider a different scenario. Assume event $C$ be "at least three dots on a die" and event $D$ as "sum of dice equals 7". Are those two events independent?
$$Pr(C) = \frac{32}{36}\\
  Pr(D) = \frac{1}{6}$$

$$Pr(C|D) = \frac{Pr(C \cap D)}{Pr(D)}=\frac{6/36}{6/36}=1$$
Thus, the two events are dependent. 

### Birthday Problem
Usually, people [underestimate the probability of finding two matching birthdays in a group](https://opinionator.blogs.nytimes.com/2012/10/01/its-my-birthday-too-yeah/) of people. Here the issue is that people think in terms of matching with their own birthday. That probability is indeed small (1 out of 365). But the matching birthday considers all combinations. Define the following two events: Event $B_2$ is that "two people have different birthdays" and event $B_3$ is that "three different birthdays of three people." The probability that two people have different birthdays is
$$Pr(B_2) = 1-\frac{1}{365}$$
and that probability that three different people have different birthdays is given by
$$Pr(B_3) = Pr(A_3|B_2) \cdot Pr(B_2)$$
$$Pr(A_3|B_2) = 1-\frac{2}{365}$$
$$Pr(B_3) = \left(1-\frac{2}{365}\right)\left(1-\frac{1}{365}\right)$$
In general, we have
$$Pr(B_n)  =Pr(A_n|B_{n-1}) \cdot Pr(B_{n-1}) = \left(1-\frac{n-1}{365}\right) \cdot
Pr(B_{n-1})= \left(1-\frac{n-1}{365}\right) \cdots \left(1-\frac{2}{365}\right)\left(1-\frac{1}{365}\right)$$
This last probability does to zero very quickly as $n$ increases. There are also other examples of [paradoxes of probability and other statistical strangeness](https://theconversation.com/paradoxes-of-probability-and-other-statistical-strangeness-74440). 

## Law of Total Probability and Bayes Rule
Suppose that you are testing a cow for mad cow disease or bovine spongiform encephalopathy (BSE). Like many medical tests, there is a chance of a false-positive. Define the event $B$ as "cow has BSE" and event $T$ as "cow tests positive." Assume that we have the following probabilities: $Pr(T|B) = 0.7$, $Pr(T|B^C) = 0.1$, $Pr(B) = 0.02$, and $Pr(B^C) = 0.98$. What is $Pr(T) = Pr(T|B) \cdot Pr(B) + Pr(T|B^C) \cdot Pr(B^C)$? Remember from conditional probability
$$Pr(T|B) = \frac{Pr(T \cap B )}{Pr(B)} \\
  Pr(T|B^C) = \frac{Pr(T \cap B^C )}{Pr(B^C)}$$
Using the provided probabilities, this can be expressed as $P(T)=0.7 \cdot 0.02 + 0.1 \cdot 0.95 = 0.112$. What is the probability that a cow has BSE if it tests positive, i.e., $P(B|T)$? The solution to this can be written as 
$$Pr(B|T)  = \frac{Pr(T \cap B )}{Pr(T)} = \frac{Pr(T|B) \cdot Pr(B)}{Pr(T|B) \cdot Pr(B) + Pr(T|B^C) \cdot Pr(B^C)}$$
Using the provided probabilities, this can be expressed as $Pr(B|T)=0.7 \cdot 0.02 / 0.112=0.125$. This can also be explained using a probability tree.

## Combinatorial Methods
### Permutations
An ordered arrangement of *k* distinct objects from a total of *n* objects is called a permutation. The number of ways of ordering *n* distinct objects taken *k* at a time is distinguished by the symbol $P_{k}^{n}$:
$$P_k^n =n \cdot (n-1) \cdot (n-2) \cdot (n-3) \cdots (n-k+1)=\frac{n!}{(n-k)!}$$
where the factorial $n!$ is defined as $n!=n \cdot (n - 1) \cdot (n - 2) \cdot (n - 3) \cdots  (2)  \cdot (1)$ with $0! = 1$. With replacement of the objects, the number of possibilities is $n^k$.

For example, consider a bowl containing six balls with the letters *A*, *B*, *C*, *D*,*E* , and *F* on the respective balls. Now consider an experiment where I draw one ball from the bowl and write down its letter and then draw a second ball and write down its letter. The outcome is then an ordered pair, i.e., $BA \neq AB$. The number of distinct ways of doing this is given by
$$P_{2}^{6}=\frac{6!}{4!}=\frac{6 \cdot 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1}{4\cdot 3 \cdot 2 \cdot 1} =6 \cdot 5=30$$
What is number of ways to arrange objects if $n=4$ and $k=2$? Without replacement, we have to calculate $P^4_2$ and with replacement, we have to calculate $n^k$.

### Combinations
A arrangement of *k* distinct objects where ordering does not matter is called a combinations. The number of unordered subsets of size *r* chosen (without replacement) from *n* available objects is
$${n \choose k} = C^n_k =  \frac{P^n_k}{k!}=\frac{n!}{k! \cdot (n-k)!}$$
What is $C_{6}^{6}$? Consider a bowl containing six balls with the letters $A$, $B$, $C$, $D$, $E$, $F$ on the respective balls. Now consider an experiment where I draw two balls from the bowl and write down the letter on each of them, not paying any attention to the order in which I draw the balls so that $AB$ is the same as $BA$. The number of distinct ways of doing this is given by
$$C_{2}^{6}=\frac{6!}{2! \cdot 4!}=\frac{6\cdot 5\cdot 4\cdot 3\cdot 2\cdot 1}{2\cdot 1\cdot 4\cdot 3 \cdot 2 \cdot 1} =\frac{6 \cdot 5}{2} =15$$
The equation for a combination with repetition is as follows:
$${n+k-1 \choose k} = \frac{(n+k-1)!}{k! \cdot (n-1)!}=\frac{(n+k-1)!}{k! \cdot (n-k)!}$$
 
## Exercises
1. *Simple Probabilities*: Calculate the following probabilities:
    a. Drawing an ace from a deck of cards? 
    b. Getting a number divisible by 3 after rolling a die? 
    c. Sum of two dice being equal to 7? 
    d. Getting at least one head after flipping a coin twice?

2. *Probability of a Union I*: Consider the two events *A* and *B* which are mutually exclusive. The probabilities associated with those two events are *Pr(A)=0.23* and *Pr(B)=0.47*. What is the probability of *A* or *B* occurring? What is the probability that neither occurs?

3. *Probability of a Union II*: Consider the probability associated with the two events *A* and *B*, i.e., *Pr(A)=0.45* and *Pr(B)=0.3*. The probability that both of those events occur at the same time, i.e., $Pr(A\cap B)$ is 0.2. What is the probability of the union?

4. *Party*: Assume that 52\% of the population are Republicans and 48\% of the population are Democrats. On a particular issue, 64\% of Republicans are in favor and 52\% of Democrats are in favor. If you randomly pick a person who is in favor of the issue, what is the probability that the person is a Democrat?

5. *Smoke Detector*: Smoke and fire detectors are essential to save lives. Unfortunately, there are many false fire alarms. Suppose that the probability of an actual fire happening is very low at 5\%. Smoke detectors are extremely good at detecting an actual fire, i.e., given a fire, there is a 99\% probability that the smoke alarm detects it. If there is no fire, there is a 10\% probability that the fire alarm sounds. Suppose that you hear a fire alarm, what is the probability that there is a fire? 

6. *Independence*: Suppose you are rolling a die. Consider the events *A* ("rolling an even number") and *B* ("rolling a number less than four"). Are *A* and *B* independent?